{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm9HlguJBtvz",
        "outputId": "f8beaa94-f629-4342-dbf2-9c39886f1971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast, json\n",
        "import os\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "\n",
        "from imblearn.pipeline import Pipeline\n",
        "from numpy import where\n",
        "from statistics import *\n",
        "from scipy.stats import chi2_contingency\n",
        "from numpy import loadtxt\n",
        "from matplotlib import pyplot\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "directory = '/content/drive/MyDrive/Research/Aqualab/Pipeline'  ###### 【Customizable item】\n",
        "os.chdir(directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh4nVkzLKDRV"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "pd.options.display.float_format = '{:.10f}'.format\n",
        "pd.set_option('display.float_format', '{:.10f}'.format)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwlZASS7FOW2"
      },
      "source": [
        "# I. Pre-process log data\n",
        "\n",
        "- Please skip this session if all .tsv files have already converted to .csv format for regression/chi-square test\n",
        "- Please make sure that all the .tsv files are in the current working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "FXnnpYCUCB7-",
        "outputId": "5ada3289-d94b-4f01-8974-153b8da91639"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_4782e97e-63c9-4540-8d75-30e21e31d08e\", \"progression_May2023.csv\", 976404)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_996fe6ae-ce4f-499a-961e-7c5652cd67fb\", \"progression_June2023.csv\", 878738)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_5cf409df-9254-4610-8dfc-5fcde56799c6\", \"progression_Aug2023.csv\", 205318)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_9dd2664a-99f0-4ad7-90ea-a1125f680ab3\", \"progression_Sept2023.csv\", 486678)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_f7c2e1b2-602a-4216-8598-20be64e26379\", \"progression_July2023.csv\", 186510)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_a61a5ad6-7b22-4554-8645-0d4a585828e3\", \"progression_Oct2023.csv\", 497183)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def data_process(data):\n",
        "    # Filter out rows where app_branch is 'develop'\n",
        "    data = data[data['app_branch'] != 'develop']\n",
        "    data = data.reset_index(drop=True)\n",
        "\n",
        "    # Sort values by user_id and timestamp\n",
        "    data = data.sort_values(by=['user_id', 'timestamp'])\n",
        "\n",
        "    # Filter out rows where event_name is 'load_error'\n",
        "    data = data[data['event_name'] != 'load_error']\n",
        "    return data\n",
        "\n",
        "def extract_job_name(game_state):\n",
        "    # extract job_name from 'game_state'\n",
        "    try:\n",
        "        game_state_dict = json.loads(game_state)\n",
        "        return game_state_dict.get('job_name', '')\n",
        "    except json.JSONDecodeError:\n",
        "        return ''\n",
        "\n",
        "def data_clean(data):\n",
        "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "    data = data[data['job_name'] != 'no-active-job']\n",
        "    data = data.reset_index(drop=False)\n",
        "    data = data.rename(columns={'level_0': 'id_org'})\n",
        "    return data\n",
        "\n",
        "def data_chunk(data):\n",
        "    # Task end when: {job differs}\n",
        "    data[\"task_status\"] = data[\"job_name\"].shift(1,fill_value=data[\"job_name\"].head(1)) != data[\"job_name\"]\n",
        "\n",
        "    # Task end when: {student changes}\n",
        "    data[\"student_change\"] = data[\"user_id\"].shift(1, fill_value=data[\"user_id\"].head(1)) != data[\"user_id\"]\n",
        "    data.loc[data[\"student_change\"] == True, \"task_status\"] = True\n",
        "\n",
        "\n",
        "    # Create task_id: whenever task status changes, task id is incremented by 1 (i.e., sum all True)\n",
        "    data['task_id'] = data['task_status'].cumsum()\n",
        "    data['task_id'] += 1\n",
        "    data['task_id'] = data['task_id'].astype(int)\n",
        "\n",
        "    # Drop task_ids that has only one row in the log file\n",
        "    task_id_counts = data['task_id'].value_counts()\n",
        "    data = data[data['task_id'].map(task_id_counts) > 1]\n",
        "    if 'id_org' in data.columns:\n",
        "        data = data.drop(columns=['id_org'], axis = 1)\n",
        "    data = data.reset_index(drop=True)\n",
        "\n",
        "    data = data.rename(columns={'job_name': 'job_string'})\n",
        "\n",
        "    # Filter rows where 'event_name' is not equal to 'complete_job' for each 'task_id'\n",
        "    filtered_data = data[data['event_name'] != 'complete_job']\n",
        "\n",
        "    # Find 'task_id' where 'user_id' is the same but 'job_string' is different in the next 'task_id'\n",
        "    task_ids = []\n",
        "    for index, row in filtered_data.iterrows():\n",
        "        current_task_id = row['task_id']\n",
        "        current_user_id = row['user_id']\n",
        "        current_job_string = row['job_string']\n",
        "\n",
        "        next_row = data.iloc[index + 1] if index + 1 < len(data) else None\n",
        "\n",
        "        if next_row is not None and next_row['user_id'] == current_user_id and next_row['job_string'] != current_job_string:\n",
        "            task_ids.append(current_task_id)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def refine_data(data):\n",
        "    # Identifying users to remove: those who only have 'kelp-welcome' as their job_string\n",
        "    users_to_remove = data.groupby('user_id')['job_string'].apply(lambda x: all(x == 'kelp-welcome'))\n",
        "    users_to_remove = users_to_remove[users_to_remove].index\n",
        "    data = data[~data['user_id'].isin(users_to_remove)]\n",
        "\n",
        "    # Remove user_id == 'default'\n",
        "    data = data[data['user_id'] != 'default']\n",
        "\n",
        "    # Adding 'task' column: counts 'complete_task' events per user per task_id\n",
        "    data['task'] = data.groupby(['user_id', 'task_id'])['event_name'].transform(lambda x: x.eq('complete_task').sum())\n",
        "\n",
        "    # Adding 'job' column: counts 'complete_job' events per user per task_id\n",
        "    data['job'] = data.groupby(['user_id', 'task_id'])['event_name'].transform(lambda x: x.eq('complete_job').sum())\n",
        "\n",
        "    # Adding 'session' column: counts 'session_id' events per user per job_string\n",
        "    data['session'] = data.groupby(['user_id', 'job_string'])['session_id'].transform(lambda x: x.nunique())\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def aggregate_rows(group):\n",
        "    # If any event is complete_job in this task_id, then this task_id has event_change column as 'Not Swapped'\n",
        "    if any(event == 'complete_job' for event in group['event_name'].values):\n",
        "        group['event_change'] = 'Not Swapped'\n",
        "    # If no event is complete_job in this task_id, then this task_id has event_change column as 'Swapped'\n",
        "    else:\n",
        "        group['event_change'] = 'Swapped'\n",
        "\n",
        "    total_time_diff = 0\n",
        "\n",
        "    # Loop through each session_id within the group\n",
        "    for session_id, session_group in group.groupby('session_id'):\n",
        "        # Calculate the time difference for the current session_id\n",
        "        time_diff = session_group['timestamp'].max() - session_group['timestamp'].min()\n",
        "        total_time_diff += abs(time_diff.total_seconds())  # Add the absolute value of time difference in seconds to total\n",
        "\n",
        "    # Assign the total time difference to the group\n",
        "    group['time_diff'] = total_time_diff\n",
        "\n",
        "    # Return the first row of the group with the required columns including the calculated total time difference\n",
        "    return group[['user_id', 'job_string', 'task_id', 'event_change', 'time_diff', 'session', 'task', 'job']].iloc[0]\n",
        "\n",
        "\n",
        "# Function to update the last row of each user_id\n",
        "def update_last_row(group):\n",
        "    group.iloc[-1, group.columns.get_loc('event_change')] = 'Not Swapped'\n",
        "    return group\n",
        "\n",
        "\n",
        "\n",
        "# Takes all .tsv file in the working directory and convert to .csv\n",
        "for filename in os.listdir('.'):\n",
        "\n",
        "    if filename.endswith('.tsv'):\n",
        "\n",
        "        data = pd.read_csv(filename, sep='\\t')\n",
        "\n",
        "        data = data_process(data)\n",
        "        data['job_name'] = data['game_state'].apply(extract_job_name)\n",
        "        data = data_clean(data)\n",
        "        data = data_chunk(data)\n",
        "\n",
        "\n",
        "        data = refine_data(data)\n",
        "\n",
        "        data = data.groupby('task_id').apply(aggregate_rows).reset_index(drop=True)\n",
        "        data = data.groupby('user_id').apply(update_last_row)\n",
        "        data = data.reset_index(drop=True)\n",
        "\n",
        "        data.to_csv(f\"progression_{filename.split('.')[0]}.csv\", index=False)\n",
        "        files.download(f\"progression_{filename.split('.')[0]}.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nFntWbs-9-R"
      },
      "source": [
        "# II. Identify Target Jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDFSgtjq8Qx4"
      },
      "outputs": [],
      "source": [
        "def concatenate_csv_files():\n",
        "    # Get all .csv files in the current working directory\n",
        "    csv_files = [file for file in os.listdir('.') if file.endswith('.csv')]\n",
        "\n",
        "    dfs = []\n",
        "\n",
        "    for csv_file in csv_files:\n",
        "        df = pd.read_csv(csv_file)\n",
        "        dfs.append(df)\n",
        "        concatenated_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    return concatenated_df\n",
        "\n",
        "data = concatenate_csv_files()\n",
        "not_completed_counts = data[data['event_change'] != 'Not Swapped'].groupby('job_string').size().reset_index(name='not_completed_count')\n",
        "total_counts = data.groupby('job_string').size().reset_index(name='total_count')\n",
        "percentage_not_completed = pd.merge(not_completed_counts, total_counts, on='job_string')\n",
        "percentage_not_completed['percentage_not_completed'] = (percentage_not_completed['not_completed_count'] / percentage_not_completed['total_count']) * 100\n",
        "top_percentage = percentage_not_completed.nlargest(100, 'percentage_not_completed')\n",
        "top_percentage = top_percentage[top_percentage['not_completed_count'] >= 30]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGNLpEICePSr"
      },
      "source": [
        "# III. Chi-square test\n",
        "\n",
        "- Please make sure that the .txt file containing all job difficulty parameters is in the current working directory.\n",
        "- Level B (LevelB) is customizable.\n",
        "- Criteria for selecting Level As is customizable (threshold_yes, threshold_no).\n",
        "- At the end of the session, the program sorts all previous levels based on chi-square statistics from high to low. It retains only a customizable number, n, of previous jobs for Session III."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2cUPhisePwS"
      },
      "outputs": [],
      "source": [
        "def diff_parameter(path):\n",
        "    para_list = []\n",
        "\n",
        "    with open(path, 'r') as file:\n",
        "        data = file.read()\n",
        "\n",
        "    # Split the data into jobs\n",
        "    jobs = data.split('\\n')\n",
        "\n",
        "    for job in jobs:\n",
        "        if job.startswith('Job:'):\n",
        "            job_info = {'Job': '', 'Experimentation': 0, 'Modeling': 0, 'Argumentation': 0}\n",
        "            job_info['Job'] = job.split('Job:')[1].strip()\n",
        "        elif job.startswith('\\tExperimentation:'):\n",
        "            job_info['Experimentation'] = int(job.split('\\tExperimentation:')[1].strip())\n",
        "        elif job.startswith('\\tModeling:'):\n",
        "            job_info['Modeling'] = int(job.split('\\tModeling:')[1].strip())\n",
        "        elif job.startswith('\\tArgumentation:'):\n",
        "            job_info['Argumentation'] = int(job.split('\\tArgumentation:')[1].strip())\n",
        "\n",
        "        para_list.append(job_info)  # Append the dictionary to the list\n",
        "\n",
        "    # Convert the list of dictionaries into a DataFrame\n",
        "    para = pd.DataFrame(para_list)\n",
        "\n",
        "    return para\n",
        "\n",
        "\n",
        "\n",
        "def process_progression_data(data):\n",
        "\n",
        "    data['time_diff'] = pd.to_numeric(data['time_diff'], errors='coerce')\n",
        "    data['job'] = pd.to_numeric(data['job'], errors='coerce')\n",
        "    data['task'] = pd.to_numeric(data['task'], errors='coerce')\n",
        "\n",
        "    data = data.drop([\"task_id\"], axis=1)\n",
        "    data = data.drop_duplicates()\n",
        "\n",
        "    data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Replace \"Not Swapped\" with NaN, and \"Swapped\" with \"switched\"\n",
        "    data = data.replace(\"Not Swapped\", np.nan)\n",
        "    data = data.replace(\"Swapped\", \"switched\")\n",
        "\n",
        "    # Combine 'job_string' and 'event_change' into 'job_status'\n",
        "    data['job_status'] = data.apply(lambda row: str(row['job_string']) + f\" ({str(row['event_change'])})\" if not pd.isna(row['event_change']) else row['job_string'], axis=1)\n",
        "\n",
        "    # Replace NaN values with \"completed\"\n",
        "    data = data.replace(np.nan, \"completed\")\n",
        "\n",
        "    # Filter out rows with 'job_string' equal to 'kelp-welcome' and reset index\n",
        "    data = data[data['job_string'] != 'kelp-welcome'].reset_index(drop=True)\n",
        "\n",
        "    # Filter out users with less than 2 entries and reset index\n",
        "    data = data.groupby('user_id').filter(lambda x: len(x) >= 2).reset_index(drop=True)\n",
        "\n",
        "    # Function to add prefix to some 'job_string'\n",
        "    def add_prefix(job_string):\n",
        "        if job_string in ['displaced-reef', 'turtle-danger', 'turtle-danger2']:\n",
        "            return 'bayou-' + job_string\n",
        "        elif job_string in ['final-final', 'above-n-below', 'completed']:\n",
        "            return 'arctic-' + job_string\n",
        "        else:\n",
        "            return job_string\n",
        "\n",
        "    data['job_string'] = data['job_string'].apply(add_prefix)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Create a dictionary to count for the number of player who completed and did not complete each job\n",
        "def create_job_dict(data, levelB):\n",
        "    job_dict = {}\n",
        "    for job in data['job_string'].unique():\n",
        "        job_dict[job] = {'yes': 0, 'no': 0}\n",
        "\n",
        "\n",
        "    for user, group in data.groupby('user_id'):\n",
        "        # Find the minimum index for 'LevelB' job\n",
        "        levelb_index = group[group['job_string'] == LevelB].index.min()\n",
        "\n",
        "        if pd.notna(levelb_index):\n",
        "          # Check each job in job_dict\n",
        "          for job in job_dict:\n",
        "              # Find rows before levelb_index for this user with the current job\n",
        "              job_rows = group[(group.index < levelb_index) & (group['job_string'] == job)]\n",
        "\n",
        "              # Check if any row has 'completed' event_change\n",
        "              if not job_rows.empty and (job_rows['event_change'] == 'completed').any():\n",
        "                  job_dict[job]['yes'] += 1\n",
        "              else:\n",
        "                  job_dict[job]['no'] += 1\n",
        "\n",
        "    return job_dict\n",
        "\n",
        "def add_values_from_para(data, para):\n",
        "    argumentation_values = []\n",
        "    modeling_values = []\n",
        "    experimentation_values = []\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        job_string = row['job_string']\n",
        "\n",
        "        # Find the row in 'para' where 'Job' matches 'job_string'\n",
        "        matching_row = para[para['Job'] == job_string]\n",
        "\n",
        "        argumentation_values.append(matching_row['Argumentation'].iloc[0] if not matching_row.empty else None)\n",
        "        modeling_values.append(matching_row['Modeling'].iloc[0] if not matching_row.empty else None)\n",
        "        experimentation_values.append(matching_row['Experimentation'].iloc[0] if not matching_row.empty else None)\n",
        "\n",
        "    data['Argumentation'] = argumentation_values\n",
        "    data['Modeling'] = modeling_values\n",
        "    data['Experimentation'] = experimentation_values\n",
        "\n",
        "    return data\n",
        "\n",
        "def get_level_A_packs(job_dict, threshold_yes, threshold_no):\n",
        "    # Filter job A base on the threshold\n",
        "    LevelApacks = []\n",
        "    for job in job_dict:\n",
        "        if job_dict[job]['yes'] >= threshold_yes and job_dict[job]['no'] >= threshold_no:\n",
        "\n",
        "            LevelApacks.append(job)\n",
        "    return LevelApacks\n",
        "\n",
        "\n",
        "def process_macro_counts(data, LevelApacks, LevelB):\n",
        "    macro_user_list_yes = []\n",
        "    macro_user_list_no = []\n",
        "    macro_counter_yes_switch = []\n",
        "    macro_counter_no_switch = []\n",
        "\n",
        "    for LevelA in LevelApacks:\n",
        "        count_yes = 0\n",
        "        user_list_yes = []\n",
        "\n",
        "        count_no = 0\n",
        "        user_list_no = []\n",
        "\n",
        "        for user, group in data.groupby('user_id'):\n",
        "            levelb_index = group[group['job_string'] == LevelB].index.min()\n",
        "\n",
        "            if pd.notna(levelb_index):\n",
        "                if (group['job_string'] == LevelA).any() and (group.index < levelb_index).any():\n",
        "                    count_yes += 1\n",
        "                    user_list_yes.append(user)\n",
        "\n",
        "                if LevelA not in group.loc[group.index < levelb_index, 'job_string'].values:\n",
        "                    count_no += 1\n",
        "                    user_list_no.append(user)\n",
        "\n",
        "        macro_user_list_yes.append(count_yes)\n",
        "        macro_user_list_no.append(count_no)\n",
        "\n",
        "        counter_yes_switch = 0\n",
        "\n",
        "        for user_id in user_list_yes:\n",
        "            user_group = data[(data['user_id'] == user_id) & (data['job_string'] == LevelB)]\n",
        "            if 'completed' not in user_group['event_change'].values:\n",
        "                counter_yes_switch += 1\n",
        "\n",
        "        macro_counter_yes_switch.append(counter_yes_switch)\n",
        "\n",
        "        counter_no_switch = 0\n",
        "\n",
        "        for user_id in user_list_no:\n",
        "            user_group = data[(data['user_id'] == user_id) & (data['job_string'] == LevelB)]\n",
        "            if 'completed' not in user_group['event_change'].values:\n",
        "                counter_no_switch += 1\n",
        "\n",
        "        macro_counter_no_switch.append(counter_no_switch)\n",
        "\n",
        "    return macro_user_list_yes, macro_user_list_no, macro_counter_yes_switch, macro_counter_no_switch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ5jgLlWiRit"
      },
      "outputs": [],
      "source": [
        "def process_dataframe(LevelApacks, LevelB, macro_user_list_yes, macro_user_list_no, macro_counter_yes_switch, macro_counter_no_switch, n):\n",
        "\n",
        "    df = pd.DataFrame(columns=['Level A', 'Level B', 'Played A before B', 'Count', '# Switched B'])\n",
        "\n",
        "\n",
        "\n",
        "    # Populate the DataFrame\n",
        "    for i, level_a in enumerate(LevelApacks):\n",
        "        for j in range(2):\n",
        "            level_b = LevelB\n",
        "            played_before_b = 'Y' if j == 0 else 'N'\n",
        "            count = macro_user_list_yes[i] if j == 0 else macro_user_list_no[i]\n",
        "            switch_b = macro_counter_yes_switch[i] if j == 0 else macro_counter_no_switch[i]\n",
        "\n",
        "            print(level_a, macro_counter_yes_switch[i], macro_counter_no_switch[i])\n",
        "\n",
        "            new_row = pd.DataFrame({'Level A': [level_a], 'Level B': [level_b], 'Played A before B': [played_before_b], 'Count': [count], '# Switched B': [switch_b]})\n",
        "            df = pd.concat([df, new_row], ignore_index=True)\n",
        "\n",
        "    if (df['# Switched B'] == 0).all():\n",
        "        return pd.DataFrame(), []\n",
        "\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    df['% Switched B'] = df['# Switched B'] / df['Count']\n",
        "\n",
        "    df['Difference'] = df.groupby('Level A')['% Switched B'].diff()\n",
        "    df['Difference'] = df.groupby('Level A')['Difference'].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "    df = df.sort_values(by=['Difference', 'Level A', 'Played A before B'], ascending=[False, True, False])\n",
        "\n",
        "    df['% Switched B'] = df['% Switched B'] * 100\n",
        "    df['% Switched B'] = df['% Switched B'].map('{:.2f}%'.format)\n",
        "\n",
        "    df['Difference'] = df['Difference'] * 100\n",
        "    df['Difference'] = df['Difference'].map('{:.2f}%'.format)\n",
        "    df.insert(5, \"# Not Switched B\", df['Count'] - df['# Switched B'])\n",
        "\n",
        "    df_grouped = df.groupby(\"Level A\")[['# Switched B', '# Not Switched B']].transform('sum')\n",
        "    df['Expected'] = ((df['# Switched B'] + df['# Not Switched B']) * df_grouped['# Switched B']) / (df_grouped['# Switched B'] + df_grouped['# Not Switched B'])\n",
        "\n",
        "    unique_levels = df['Level A'].unique()\n",
        "    chi_stats = []\n",
        "    p_values = []\n",
        "\n",
        "    for level in unique_levels:\n",
        "        subset = df[df['Level A'] == level]\n",
        "        observed = subset['# Switched B'].tolist()\n",
        "        expected = subset['Expected'].tolist()\n",
        "\n",
        "        observed_forchi2 = subset[['# Switched B', '# Not Switched B']].copy()\n",
        "\n",
        "        # Perform chi-square test\n",
        "        chi2, p, _, _ = chi2_contingency(observed_forchi2)\n",
        "        chi_stats.append(chi2)\n",
        "        p_values.append(p)\n",
        "\n",
        "    result_df = pd.DataFrame({'Level A': unique_levels, 'Chi-Square Statistic': chi_stats, 'p-value': p_values})\n",
        "    df = df.merge(result_df, on='Level A', how='left')\n",
        "\n",
        "    ######### Modify the DataFrame to keep only the first n*2 rows #########\n",
        "    ######### Extract and return the first n \"Level A\" values #########\n",
        "\n",
        "\n",
        "    if len(df) < 2 * n:\n",
        "      # If it does, keep whatever rows it has\n",
        "        df = df\n",
        "        level_a_first_n = df['Level A'].unique().tolist()\n",
        "    else:\n",
        "      # If it has 2*n rows or more, keep only the first n*2 rows\n",
        "        df = df.iloc[:n*2]\n",
        "        level_a_first_n = df['Level A'].iloc[range(0, n*2, 2)].unique().tolist()\n",
        "\n",
        "    return df, level_a_first_n\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRol_hFg_4iz"
      },
      "outputs": [],
      "source": [
        "path_to_file = 'JobText.txt'\n",
        "para = diff_parameter(path_to_file)\n",
        "data = process_progression_data(data)\n",
        "data = add_values_from_para(data, para)\n",
        "final_dataframe = pd.DataFrame()\n",
        "level_a_first_n_dict = {}\n",
        "\n",
        "\n",
        "for job in top_percentage['job_string']:\n",
        "\n",
        "    LevelB = job\n",
        "    job_dict = create_job_dict(data, LevelB)\n",
        "    LevelApacks = get_level_A_packs(job_dict, threshold_yes=30, threshold_no=30)\n",
        "    macro_user_list_yes, macro_user_list_no, macro_counter_yes_switch, macro_counter_no_switch = process_macro_counts(data, LevelApacks, LevelB)\n",
        "    result_dataframe, level_a_first_n = process_dataframe(LevelApacks, LevelB, macro_user_list_yes, macro_user_list_no, macro_counter_yes_switch, macro_counter_no_switch, n=3)\n",
        "    final_dataframe = pd.concat([final_dataframe, result_dataframe])\n",
        "    level_a_first_n_dict[job] = level_a_first_n\n",
        "\n",
        "\n",
        "final_dataframe.reset_index(drop=True, inplace=True)\n",
        "final_dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUDgaJx0JqMW"
      },
      "source": [
        "# IV. Construct regression table\n",
        "\n",
        "- This section only consider the n number (defined in Session II) of previous jobs prior to the target job with the highest chi-square coefficient to compile the regression table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p-_XiMSUPRL"
      },
      "outputs": [],
      "source": [
        "def process_levels(data, LevelApacks, LevelB, num_check):\n",
        "    num_levelA = 1\n",
        "    final_dataframe = pd.DataFrame()\n",
        "\n",
        "\n",
        "    for LevelA in LevelApacks:\n",
        "        if num_levelA > num_check:\n",
        "            break\n",
        "\n",
        "        if LevelA == \"kelp-shop-welcome\":\n",
        "            continue\n",
        "\n",
        "        print(\"**--------------------------------\", LevelA, \"--------------------------------**\")\n",
        "\n",
        "        x = pd.DataFrame(columns=['user_id', 'Level', 'Complete_A', 'Complete_B',\n",
        "                                  'Arg_above_2', 'Mod_above_2', 'Exp_above_2',\n",
        "                                  'Time', 'Job', 'Task', 'Biome', 'Session'])\n",
        "\n",
        "        # Filter user IDs for LevelB\n",
        "        user_ids_levelb = data[data['job_string'] == LevelB]['user_id'].unique()\n",
        "\n",
        "        # Iterate over each user_id\n",
        "        for user_id in user_ids_levelb:\n",
        "            user_data = data[data['user_id'] == user_id]\n",
        "            levelb_index = user_data[user_data['job_string'] == LevelB].index.min()\n",
        "\n",
        "\n",
        "            #【Feature 1-2: Complete_A, Complete_B】: Calculate Complete_A and Complete_B\n",
        "\n",
        "            # Identify rows where both conditions are met\n",
        "            complete_a = 1 if any((user_data['job_string'] == LevelA) & (user_data['event_change'] == 'completed')) else 0\n",
        "            complete_b = 1 if any((user_data['job_string'] == LevelB) & (user_data['event_change'] == 'completed')) else 0\n",
        "\n",
        "\n",
        "            #【Feature 3-5: unique_job_arg_count, unique_job_mod_count, unique_job_exp_count】: Count the number of jobs [completed] where each difficulty parameter > 2\n",
        "            # Select rows up to and including the first 'LevelB' occurrence\n",
        "            levelb_index = user_data[user_data['job_string'] == LevelB].index.min()\n",
        "            user_data_levelb = user_data.loc[:levelb_index]\n",
        "\n",
        "            filtered_df = user_data_levelb[user_data_levelb['event_change'] == 'completed']   # Which jobs has the student completed so far?\n",
        "                                                                                              # Please change 'filtered_df' to 'user_data_levelb' if we want to include any job student has accepted\n",
        "\n",
        "            unique_job_arg_count = filtered_df[filtered_df['Argumentation'] > 2]['job_string'].nunique()\n",
        "            unique_job_mod_count = filtered_df[filtered_df['Modeling'] > 2]['job_string'].nunique()\n",
        "            unique_job_exp_count = filtered_df[filtered_df['Experimentation'] > 2]['job_string'].nunique()\n",
        "\n",
        "            #【Feature 6: time_diff】: Time spent so far in hours\n",
        "            time_diff  = user_data['time_diff'].sum() / 3600\n",
        "\n",
        "            #【Feature 7-8: job_sum, task_sum】: Sum Job and Task student has completed\n",
        "            job_sum = user_data_levelb['job'].sum()\n",
        "            task_sum = user_data_levelb['task'].sum()\n",
        "\n",
        "            #【Feature 9: Biome】: Number of Biome Student has been to\n",
        "            biome = user_data_levelb['job_string'].str.split('-').str[0].nunique()\n",
        "\n",
        "            #【Feature 10: time_diff】: Time paused (unique session id) so far\n",
        "            session  = user_data['session'].sum() - 1\n",
        "\n",
        "\n",
        "            # Append to DataFrame x\n",
        "            new_row = {'user_id': user_id, 'Level': LevelA, 'Complete_A': complete_a, 'Complete_B': complete_b,\n",
        "                      'Arg_above_2': unique_job_arg_count, 'Mod_above_2': unique_job_mod_count, 'Exp_above_2': unique_job_exp_count,\n",
        "                      'Time': time_diff, 'Job': job_sum, 'Task': task_sum, 'Biome': biome, 'Session': session}\n",
        "\n",
        "\n",
        "            x = pd.concat([x, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "        # Drop rows where any NaN values exist due to incomplete log file\n",
        "        x = x.dropna()\n",
        "\n",
        "        # If Biome is the same all the time, drop it\n",
        "        if x['Biome'].nunique() == 1:\n",
        "          x = x.drop_duplicates(subset='Biome', keep=False)\n",
        "\n",
        "        # Selecting the independent variables (excluding 'user_id' and 'Complete_B')\n",
        "        X = x.drop(['user_id', 'Complete_B', 'Level'], axis=1)\n",
        "\n",
        "        # Adding a constant to the model (intercept)\n",
        "        X = sm.add_constant(X)\n",
        "\n",
        "        # The dependent variable\n",
        "        y = x['Complete_B']\n",
        "\n",
        "\n",
        "        model = sm.Logit(y.astype(float), X.astype(float))\n",
        "        result = model.fit(method='bfgs', maxiter=100, tol=1e-2)\n",
        "\n",
        "\n",
        "        # Print the p-value for 'Complete_A'\n",
        "        # p_value_complete_a = result.pvalues['Complete_A']\n",
        "        # print(f\"P-value for {LevelA}: {p_value_complete_a}\")\n",
        "\n",
        "        num_levelA += 1\n",
        "\n",
        "        # Access the summary data\n",
        "        summary_data = result.summary2().tables[1]\n",
        "\n",
        "        # Convert the summary data to a DataFrame\n",
        "        df_summary = pd.DataFrame(summary_data)\n",
        "        level_a_row = pd.DataFrame({'LevelA': [LevelA]})\n",
        "\n",
        "        final_dataframe = pd.concat([final_dataframe, level_a_row, df_summary])\n",
        "\n",
        "\n",
        "    return final_dataframe\n",
        "\n",
        "\n",
        "final_dataframe = pd.DataFrame()\n",
        "\n",
        "for LevelB in level_a_first_n_dict:\n",
        "  level_b_row = pd.DataFrame({'LevelB': [LevelB]})\n",
        "  final_dataframe = pd.concat([final_dataframe, level_b_row])\n",
        "  LevelApacks = level_a_first_n_dict[LevelB]\n",
        "\n",
        "  result_dataframe = process_levels(data, LevelApacks, LevelB, num_check = 300)  ###### 【Customizable item】\n",
        "  final_dataframe = pd.concat([final_dataframe, result_dataframe])\n",
        "\n",
        "\n",
        "final_dataframe = final_dataframe.reset_index()\n",
        "final_dataframe.rename(columns={'index': 'Variable'}, inplace=True)\n",
        "final_dataframe['Variable'] = final_dataframe['Variable'].replace(0, np.nan)\n",
        "columns_ordered = ['LevelB', 'LevelA', 'Variable', 'Coef.', 'Std.Err.', 'z', 'P>|z|', '[0.025', '0.975]']\n",
        "final_dataframe = final_dataframe[columns_ordered]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "h2BhMDYSo9SV",
        "outputId": "3120fae5-b5c9-4529-b7e6-00040b83c2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     LevelB               LevelA     Variable         Coef.  \\\n",
              "0       coral-hunting-lions                  NaN          NaN           NaN   \n",
              "1                       NaN  bayou-reef-decision          NaN           NaN   \n",
              "2                       NaN                  NaN        const -0.0557888943   \n",
              "3                       NaN                  NaN   Complete_A  1.5536130657   \n",
              "4                       NaN                  NaN  Arg_above_2 -0.0748432561   \n",
              "...                     ...                  ...          ...           ...   \n",
              "1173                    NaN                  NaN          Job  1.2359287238   \n",
              "1174                    NaN                  NaN         Task -0.1614867305   \n",
              "1175                    NaN                  NaN        Biome -0.9317869148   \n",
              "1176                    NaN                  NaN      Session -0.0024605352   \n",
              "1177  kelp-bull-kelp-forest                  NaN          NaN           NaN   \n",
              "\n",
              "         Std.Err.             z        P>|z|        [0.025        0.975]  \n",
              "0             NaN           NaN          NaN           NaN           NaN  \n",
              "1             NaN           NaN          NaN           NaN           NaN  \n",
              "2    0.6609289513 -0.0844098208 0.9327305993 -1.3511858352  1.2396080466  \n",
              "3    0.3091909833  5.0247683460 0.0000005040  0.9476098741  2.1596162573  \n",
              "4    0.0969113920 -0.7722854307 0.4399453925 -0.2647860940  0.1150995819  \n",
              "...           ...           ...          ...           ...           ...  \n",
              "1173 0.3507628849  3.5235447561 0.0004258152  0.5484461022  1.9234113453  \n",
              "1174 0.1777164633 -0.9086762559 0.3635210412 -0.5098045980  0.1868311370  \n",
              "1175 0.3132586939 -2.9744965831 0.0029346972 -1.5457626727 -0.3178111568  \n",
              "1176 0.0083645911 -0.2941608498 0.7686349951 -0.0188548324  0.0139337620  \n",
              "1177          NaN           NaN          NaN           NaN           NaN  \n",
              "\n",
              "[1178 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62cbb656-e7be-4116-98f4-335dfd51354a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LevelB</th>\n",
              "      <th>LevelA</th>\n",
              "      <th>Variable</th>\n",
              "      <th>Coef.</th>\n",
              "      <th>Std.Err.</th>\n",
              "      <th>z</th>\n",
              "      <th>P&gt;|z|</th>\n",
              "      <th>[0.025</th>\n",
              "      <th>0.975]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>coral-hunting-lions</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>bayou-reef-decision</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>const</td>\n",
              "      <td>-0.0557888943</td>\n",
              "      <td>0.6609289513</td>\n",
              "      <td>-0.0844098208</td>\n",
              "      <td>0.9327305993</td>\n",
              "      <td>-1.3511858352</td>\n",
              "      <td>1.2396080466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Complete_A</td>\n",
              "      <td>1.5536130657</td>\n",
              "      <td>0.3091909833</td>\n",
              "      <td>5.0247683460</td>\n",
              "      <td>0.0000005040</td>\n",
              "      <td>0.9476098741</td>\n",
              "      <td>2.1596162573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Arg_above_2</td>\n",
              "      <td>-0.0748432561</td>\n",
              "      <td>0.0969113920</td>\n",
              "      <td>-0.7722854307</td>\n",
              "      <td>0.4399453925</td>\n",
              "      <td>-0.2647860940</td>\n",
              "      <td>0.1150995819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1173</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Job</td>\n",
              "      <td>1.2359287238</td>\n",
              "      <td>0.3507628849</td>\n",
              "      <td>3.5235447561</td>\n",
              "      <td>0.0004258152</td>\n",
              "      <td>0.5484461022</td>\n",
              "      <td>1.9234113453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1174</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Task</td>\n",
              "      <td>-0.1614867305</td>\n",
              "      <td>0.1777164633</td>\n",
              "      <td>-0.9086762559</td>\n",
              "      <td>0.3635210412</td>\n",
              "      <td>-0.5098045980</td>\n",
              "      <td>0.1868311370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1175</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Biome</td>\n",
              "      <td>-0.9317869148</td>\n",
              "      <td>0.3132586939</td>\n",
              "      <td>-2.9744965831</td>\n",
              "      <td>0.0029346972</td>\n",
              "      <td>-1.5457626727</td>\n",
              "      <td>-0.3178111568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1176</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Session</td>\n",
              "      <td>-0.0024605352</td>\n",
              "      <td>0.0083645911</td>\n",
              "      <td>-0.2941608498</td>\n",
              "      <td>0.7686349951</td>\n",
              "      <td>-0.0188548324</td>\n",
              "      <td>0.0139337620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1177</th>\n",
              "      <td>kelp-bull-kelp-forest</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1178 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62cbb656-e7be-4116-98f4-335dfd51354a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-62cbb656-e7be-4116-98f4-335dfd51354a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-62cbb656-e7be-4116-98f4-335dfd51354a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d1356f5-12b8-4d17-b2bc-7aa093cc9461\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d1356f5-12b8-4d17-b2bc-7aa093cc9461')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d1356f5-12b8-4d17-b2bc-7aa093cc9461 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_dataframe",
              "summary": "{\n  \"name\": \"final_dataframe\",\n  \"rows\": 1178,\n  \"fields\": [\n    {\n      \"column\": \"LevelB\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 45,\n        \"samples\": [\n          \"kelp-urchin-barren-predict\",\n          \"bayou-shrimp-yields\",\n          \"coral-fake-fix\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LevelA\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"arctic-salmon-competition\",\n          \"arctic-missing-whale\",\n          \"arctic-endangered-seals\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Variable\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Biome\",\n          \"Complete_A\",\n          \"Time\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coef.\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.78290564968941,\n        \"min\": -19.7544442165393,\n        \"max\": 80.47051514743443,\n        \"num_unique_values\": 1030,\n        \"samples\": [\n          1.2447660978272337,\n          0.0016429147045762304,\n          0.35359754692409523\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Std.Err.\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96574.16953344707,\n        \"min\": 0.0006707385787795706,\n        \"max\": 2356178.036037672,\n        \"num_unique_values\": 1030,\n        \"samples\": [\n          0.2967179671709072,\n          0.004867715300821951,\n          0.10929894546485977\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.088562359620466,\n        \"min\": -6.318375738951503,\n        \"max\": 8.761850323628604,\n        \"num_unique_values\": 1030,\n        \"samples\": [\n          4.19511534706039,\n          0.3375124885177265,\n          3.235141431787911\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"P>|z|\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3160574863926811,\n        \"min\": 1.9207119992938374e-18,\n        \"max\": 0.9999999959630402,\n        \"num_unique_values\": 1030,\n        \"samples\": [\n          2.7273275927985363e-05,\n          0.7357305994127024,\n          0.00121582489655971\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"[0.025\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 189281.84892049604,\n        \"min\": -4618024.138476234,\n        \"max\": 5.660157569104416,\n        \"num_unique_values\": 1030,\n        \"samples\": [\n          0.6632095686063174,\n          -0.007897631972029348,\n          0.13937555026476262\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0.975]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 189281.9394451942,\n        \"min\": -3.2155658126186903,\n        \"max\": 4618024.045120075,\n        \"num_unique_values\": 1030,\n        \"samples\": [\n          1.82632262704815,\n          0.011183461381181807,\n          0.5678195435834279\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}