{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm9HlguJBtvz",
        "outputId": "e13457cb-35ee-49bf-8b4d-b52ef6012a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast, json\n",
        "import os\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "\n",
        "from imblearn.pipeline import Pipeline\n",
        "from numpy import where\n",
        "from statistics import *\n",
        "from scipy.stats import chi2_contingency\n",
        "from numpy import loadtxt\n",
        "from matplotlib import pyplot\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "directory = '/content/drive/MyDrive/Research/Aqualab/Pipeline'  ###### 【Customizable item】\n",
        "os.chdir(directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Rh4nVkzLKDRV"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "pd.options.display.float_format = '{:.10f}'.format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwlZASS7FOW2"
      },
      "source": [
        "# I. Pre-process log data\n",
        "\n",
        "- Please skip this session if all .tsv files have already converted to .csv format for regression/chi-square test\n",
        "- Please make sure that all the .tsv files are in the current working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "FXnnpYCUCB7-",
        "outputId": "5ada3289-d94b-4f01-8974-153b8da91639"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_4782e97e-63c9-4540-8d75-30e21e31d08e\", \"progression_May2023.csv\", 976404)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_996fe6ae-ce4f-499a-961e-7c5652cd67fb\", \"progression_June2023.csv\", 878738)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_5cf409df-9254-4610-8dfc-5fcde56799c6\", \"progression_Aug2023.csv\", 205318)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_9dd2664a-99f0-4ad7-90ea-a1125f680ab3\", \"progression_Sept2023.csv\", 486678)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f7c2e1b2-602a-4216-8598-20be64e26379\", \"progression_July2023.csv\", 186510)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a61a5ad6-7b22-4554-8645-0d4a585828e3\", \"progression_Oct2023.csv\", 497183)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def data_process(data):\n",
        "    # Filter out rows where app_branch is 'develop'\n",
        "    data = data[data['app_branch'] != 'develop']\n",
        "    data = data.reset_index(drop=True)\n",
        "\n",
        "    # Sort values by user_id and timestamp\n",
        "    data = data.sort_values(by=['user_id', 'timestamp'])\n",
        "\n",
        "    # Filter out rows where event_name is 'load_error'\n",
        "    data = data[data['event_name'] != 'load_error']\n",
        "    return data\n",
        "\n",
        "def extract_job_name(game_state):\n",
        "    # extract job_name from 'game_state'\n",
        "    try:\n",
        "        game_state_dict = json.loads(game_state)\n",
        "        return game_state_dict.get('job_name', '')\n",
        "    except json.JSONDecodeError:\n",
        "        return ''\n",
        "\n",
        "def data_clean(data):\n",
        "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "    data = data[data['job_name'] != 'no-active-job']\n",
        "    data = data.reset_index(drop=False)\n",
        "    data = data.rename(columns={'level_0': 'id_org'})\n",
        "    return data\n",
        "\n",
        "def data_chunk(data):\n",
        "    # Task end when: {job differs}\n",
        "    data[\"task_status\"] = data[\"job_name\"].shift(1,fill_value=data[\"job_name\"].head(1)) != data[\"job_name\"]\n",
        "\n",
        "    # Task end when: {student changes}\n",
        "    data[\"student_change\"] = data[\"user_id\"].shift(1, fill_value=data[\"user_id\"].head(1)) != data[\"user_id\"]\n",
        "    data.loc[data[\"student_change\"] == True, \"task_status\"] = True\n",
        "\n",
        "\n",
        "    # Create task_id: whenever task status changes, task id is incremented by 1 (i.e., sum all True)\n",
        "    data['task_id'] = data['task_status'].cumsum()\n",
        "    data['task_id'] += 1\n",
        "    data['task_id'] = data['task_id'].astype(int)\n",
        "\n",
        "    # Drop task_ids that has only one row in the log file\n",
        "    task_id_counts = data['task_id'].value_counts()\n",
        "    data = data[data['task_id'].map(task_id_counts) > 1]\n",
        "    if 'id_org' in data.columns:\n",
        "        data = data.drop(columns=['id_org'], axis = 1)\n",
        "    data = data.reset_index(drop=True)\n",
        "\n",
        "    data = data.rename(columns={'job_name': 'job_string'})\n",
        "\n",
        "    # Filter rows where 'event_name' is not equal to 'complete_job' for each 'task_id'\n",
        "    filtered_data = data[data['event_name'] != 'complete_job']\n",
        "\n",
        "    # Find 'task_id' where 'user_id' is the same but 'job_string' is different in the next 'task_id'\n",
        "    task_ids = []\n",
        "    for index, row in filtered_data.iterrows():\n",
        "        current_task_id = row['task_id']\n",
        "        current_user_id = row['user_id']\n",
        "        current_job_string = row['job_string']\n",
        "\n",
        "        next_row = data.iloc[index + 1] if index + 1 < len(data) else None\n",
        "\n",
        "        if next_row is not None and next_row['user_id'] == current_user_id and next_row['job_string'] != current_job_string:\n",
        "            task_ids.append(current_task_id)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def refine_data(data):\n",
        "    # Identifying users to remove: those who only have 'kelp-welcome' as their job_string\n",
        "    users_to_remove = data.groupby('user_id')['job_string'].apply(lambda x: all(x == 'kelp-welcome'))\n",
        "    users_to_remove = users_to_remove[users_to_remove].index\n",
        "    data = data[~data['user_id'].isin(users_to_remove)]\n",
        "\n",
        "    # Remove user_id == 'default'\n",
        "    data = data[data['user_id'] != 'default']\n",
        "\n",
        "    # Adding 'task' column: counts 'complete_task' events per user per task_id\n",
        "    data['task'] = data.groupby(['user_id', 'task_id'])['event_name'].transform(lambda x: x.eq('complete_task').sum())\n",
        "\n",
        "    # Adding 'job' column: counts 'complete_job' events per user per task_id\n",
        "    data['job'] = data.groupby(['user_id', 'task_id'])['event_name'].transform(lambda x: x.eq('complete_job').sum())\n",
        "\n",
        "    # Adding 'session' column: counts 'session_id' events per user per job_string\n",
        "    data['session'] = data.groupby(['user_id', 'job_string'])['session_id'].transform(lambda x: x.nunique())\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def aggregate_rows(group):\n",
        "    # If any event is complete_job in this task_id, then this task_id has event_change column as 'Not Swapped'\n",
        "    if any(event == 'complete_job' for event in group['event_name'].values):\n",
        "        group['event_change'] = 'Not Swapped'\n",
        "    # If no event is complete_job in this task_id, then this task_id has event_change column as 'Swapped'\n",
        "    else:\n",
        "        group['event_change'] = 'Swapped'\n",
        "\n",
        "    total_time_diff = 0\n",
        "\n",
        "    # Loop through each session_id within the group\n",
        "    for session_id, session_group in group.groupby('session_id'):\n",
        "        # Calculate the time difference for the current session_id\n",
        "        time_diff = session_group['timestamp'].max() - session_group['timestamp'].min()\n",
        "        total_time_diff += abs(time_diff.total_seconds())  # Add the absolute value of time difference in seconds to total\n",
        "\n",
        "    # Assign the total time difference to the group\n",
        "    group['time_diff'] = total_time_diff\n",
        "\n",
        "    # Return the first row of the group with the required columns including the calculated total time difference\n",
        "    return group[['user_id', 'job_string', 'task_id', 'event_change', 'time_diff', 'session', 'task', 'job']].iloc[0]\n",
        "\n",
        "\n",
        "# Function to update the last row of each user_id\n",
        "def update_last_row(group):\n",
        "    group.iloc[-1, group.columns.get_loc('event_change')] = 'Not Swapped'\n",
        "    return group\n",
        "\n",
        "\n",
        "\n",
        "# Takes all .tsv file in the working directory and convert to .csv\n",
        "for filename in os.listdir('.'):\n",
        "\n",
        "    if filename.endswith('.tsv'):\n",
        "\n",
        "        data = pd.read_csv(filename, sep='\\t')\n",
        "\n",
        "        data = data_process(data)\n",
        "        data['job_name'] = data['game_state'].apply(extract_job_name)\n",
        "        data = data_clean(data)\n",
        "        data = data_chunk(data)\n",
        "\n",
        "\n",
        "        data = refine_data(data)\n",
        "\n",
        "        data = data.groupby('task_id').apply(aggregate_rows).reset_index(drop=True)\n",
        "        data = data.groupby('user_id').apply(update_last_row)\n",
        "        data = data.reset_index(drop=True)\n",
        "\n",
        "        data.to_csv(f\"progression_{filename.split('.')[0]}.csv\", index=False)\n",
        "        files.download(f\"progression_{filename.split('.')[0]}.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGNLpEICePSr"
      },
      "source": [
        "# II. Chi-square test\n",
        "\n",
        "- Please make sure that the .txt file for all job difficulty parameters are in the current working directory\n",
        "- Level B (LevelB) is customizable\n",
        "- Criteria for selecting Level As is customizable (threshold_yes, threshold_no)\n",
        "- At the end of the session, the program will sort all previous levels based on the chi-square statistics from high to low. It will then retain only a customizable number, n, of previous jobs for Session III.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C2cUPhisePwS"
      },
      "outputs": [],
      "source": [
        "def diff_parameter(path):\n",
        "    para_list = []\n",
        "\n",
        "    with open(path, 'r') as file:\n",
        "        data = file.read()\n",
        "\n",
        "    # Split the data into jobs\n",
        "    jobs = data.split('\\n')\n",
        "\n",
        "    for job in jobs:\n",
        "        if job.startswith('Job:'):\n",
        "            job_info = {'Job': '', 'Experimentation': 0, 'Modeling': 0, 'Argumentation': 0}\n",
        "            job_info['Job'] = job.split('Job:')[1].strip()\n",
        "        elif job.startswith('\\tExperimentation:'):\n",
        "            job_info['Experimentation'] = int(job.split('\\tExperimentation:')[1].strip())\n",
        "        elif job.startswith('\\tModeling:'):\n",
        "            job_info['Modeling'] = int(job.split('\\tModeling:')[1].strip())\n",
        "        elif job.startswith('\\tArgumentation:'):\n",
        "            job_info['Argumentation'] = int(job.split('\\tArgumentation:')[1].strip())\n",
        "\n",
        "        para_list.append(job_info)  # Append the dictionary to the list\n",
        "\n",
        "    # Convert the list of dictionaries into a DataFrame\n",
        "    para = pd.DataFrame(para_list)\n",
        "\n",
        "    return para\n",
        "\n",
        "\n",
        "def concatenate_csv_files():\n",
        "    # Get all .csv files in the current working directory\n",
        "    csv_files = [file for file in os.listdir('.') if file.endswith('.csv')]\n",
        "\n",
        "    dfs = []\n",
        "\n",
        "    for csv_file in csv_files:\n",
        "        df = pd.read_csv(csv_file)\n",
        "        dfs.append(df)\n",
        "        concatenated_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    return concatenated_df\n",
        "\n",
        "def process_progression_data(data):\n",
        "\n",
        "    data['time_diff'] = pd.to_numeric(data['time_diff'], errors='coerce')\n",
        "    data['job'] = pd.to_numeric(data['job'], errors='coerce')\n",
        "    data['task'] = pd.to_numeric(data['task'], errors='coerce')\n",
        "\n",
        "    data = data.drop([\"task_id\"], axis=1)\n",
        "    data = data.drop_duplicates()\n",
        "\n",
        "    data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Replace \"Not Swapped\" with NaN, and \"Swapped\" with \"switched\"\n",
        "    data = data.replace(\"Not Swapped\", np.nan)\n",
        "    data = data.replace(\"Swapped\", \"switched\")\n",
        "\n",
        "    # Combine 'job_string' and 'event_change' into 'job_status'\n",
        "    data['job_status'] = data.apply(lambda row: str(row['job_string']) + f\" ({str(row['event_change'])})\" if not pd.isna(row['event_change']) else row['job_string'], axis=1)\n",
        "\n",
        "    # Replace NaN values with \"completed\"\n",
        "    data = data.replace(np.nan, \"completed\")\n",
        "\n",
        "    # Filter out rows with 'job_string' equal to 'kelp-welcome' and reset index\n",
        "    data = data[data['job_string'] != 'kelp-welcome'].reset_index(drop=True)\n",
        "\n",
        "    # Filter out users with less than 2 entries and reset index\n",
        "    data = data.groupby('user_id').filter(lambda x: len(x) >= 2).reset_index(drop=True)\n",
        "\n",
        "    # Function to add prefix to some 'job_string'\n",
        "    def add_prefix(job_string):\n",
        "        if job_string in ['displaced-reef', 'turtle-danger', 'turtle-danger2']:\n",
        "            return 'bayou-' + job_string\n",
        "        elif job_string in ['final-final', 'above-n-below', 'completed']:\n",
        "            return 'arctic-' + job_string\n",
        "        else:\n",
        "            return job_string\n",
        "\n",
        "    data['job_string'] = data['job_string'].apply(add_prefix)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Create a dictionary to count for the number of player who completed and did not complete each job\n",
        "def create_job_dict(data, levelB):\n",
        "    job_dict = {}\n",
        "    for job in data['job_string'].unique():\n",
        "        job_dict[job] = {'yes': 0, 'no': 0}\n",
        "\n",
        "\n",
        "    for user, group in data.groupby('user_id'):\n",
        "        # Find the minimum index for 'LevelB' job\n",
        "        levelb_index = group[group['job_string'] == LevelB].index.min()\n",
        "\n",
        "        if pd.notna(levelb_index):\n",
        "          # Check each job in job_dict\n",
        "          for job in job_dict:\n",
        "              # Find rows before levelb_index for this user with the current job\n",
        "              job_rows = group[(group.index < levelb_index) & (group['job_string'] == job)]\n",
        "\n",
        "              # Check if any row has 'completed' event_change\n",
        "              if not job_rows.empty and (job_rows['event_change'] == 'completed').any():\n",
        "                  job_dict[job]['yes'] += 1\n",
        "              else:\n",
        "                  job_dict[job]['no'] += 1\n",
        "\n",
        "    return job_dict\n",
        "\n",
        "def add_values_from_para(data, para):\n",
        "    argumentation_values = []\n",
        "    modeling_values = []\n",
        "    experimentation_values = []\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        job_string = row['job_string']\n",
        "\n",
        "        # Find the row in 'para' where 'Job' matches 'job_string'\n",
        "        matching_row = para[para['Job'] == job_string]\n",
        "\n",
        "        argumentation_values.append(matching_row['Argumentation'].iloc[0] if not matching_row.empty else None)\n",
        "        modeling_values.append(matching_row['Modeling'].iloc[0] if not matching_row.empty else None)\n",
        "        experimentation_values.append(matching_row['Experimentation'].iloc[0] if not matching_row.empty else None)\n",
        "\n",
        "    data['Argumentation'] = argumentation_values\n",
        "    data['Modeling'] = modeling_values\n",
        "    data['Experimentation'] = experimentation_values\n",
        "\n",
        "    return data\n",
        "\n",
        "def get_level_A_packs(job_dict, threshold_yes, threshold_no):\n",
        "    # Filter job A base on the threshold\n",
        "    LevelApacks = []\n",
        "    for job in job_dict:\n",
        "        if job_dict[job]['yes'] >= threshold_yes and job_dict[job]['no'] >= threshold_no:\n",
        "            LevelApacks.append(job)\n",
        "    return LevelApacks\n",
        "\n",
        "\n",
        "def process_macro_counts(data, LevelApacks, LevelB):\n",
        "    macro_user_list_yes = []\n",
        "    macro_user_list_no = []\n",
        "    macro_counter_yes_switch = []\n",
        "    macro_counter_no_switch = []\n",
        "\n",
        "    for LevelA in LevelApacks:\n",
        "        count_yes = 0\n",
        "        user_list_yes = []\n",
        "\n",
        "        count_no = 0\n",
        "        user_list_no = []\n",
        "\n",
        "        for user, group in data.groupby('user_id'):\n",
        "            levelb_index = group[group['job_string'] == LevelB].index.min()\n",
        "\n",
        "            if pd.notna(levelb_index):\n",
        "                if (group['job_string'] == LevelA).any() and (group.index < levelb_index).any():\n",
        "                    count_yes += 1\n",
        "                    user_list_yes.append(user)\n",
        "\n",
        "                if LevelA not in group.loc[group.index < levelb_index, 'job_string'].values:\n",
        "                    count_no += 1\n",
        "                    user_list_no.append(user)\n",
        "\n",
        "        macro_user_list_yes.append(count_yes)\n",
        "        macro_user_list_no.append(count_no)\n",
        "\n",
        "        counter_yes_switch = 0\n",
        "\n",
        "        for user_id in user_list_yes:\n",
        "            user_group = data[(data['user_id'] == user_id) & (data['job_string'] == LevelB)]\n",
        "            if 'completed' not in user_group['event_change'].values:\n",
        "                counter_yes_switch += 1\n",
        "\n",
        "        macro_counter_yes_switch.append(counter_yes_switch)\n",
        "\n",
        "        counter_no_switch = 0\n",
        "\n",
        "        for user_id in user_list_no:\n",
        "            user_group = data[(data['user_id'] == user_id) & (data['job_string'] == LevelB)]\n",
        "            if 'completed' not in user_group['event_change'].values:\n",
        "                counter_no_switch += 1\n",
        "\n",
        "        macro_counter_no_switch.append(counter_no_switch)\n",
        "\n",
        "    return macro_user_list_yes, macro_user_list_no, macro_counter_yes_switch, macro_counter_no_switch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "16OCq5MpiXtT"
      },
      "outputs": [],
      "source": [
        "LevelB = 'coral-hunting-lions' ###### 【Customizable item】"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1Ztqv16aepMM"
      },
      "outputs": [],
      "source": [
        "data = concatenate_csv_files()\n",
        "path_to_file = 'JobText.txt'\n",
        "para = diff_parameter(path_to_file)\n",
        "data = process_progression_data(data)\n",
        "job_dict = create_job_dict(data, LevelB)\n",
        "data = add_values_from_para(data, para)\n",
        "LevelApacks = get_level_A_packs(job_dict, threshold_yes = 30, threshold_no = 30)  ###### 【Customizable item】\n",
        "macro_user_list_yes, macro_user_list_no, macro_counter_yes_switch, macro_counter_no_switch = process_macro_counts(data, LevelApacks, LevelB)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "RJ5jgLlWiRit",
        "outputId": "23a08f2f-daf9-4ebe-d52f-634635e9ed87"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"result_dataframe\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Level A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"bayou-reef-decision\",\n          \"bayou-hide-n-seek\",\n          \"bayou-methanogen\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Level B\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"coral-hunting-lions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Played A before B\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Count\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 124,\n        \"max\": 362,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"# Switched B\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 20,\n        \"max\": 153,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"# Not Switched B\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 104,\n        \"max\": 209,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          104\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"% Switched B\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"16.13%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Difference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"26.14%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Expected\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 44.13991769547325,\n        \"max\": 128.86008230452674,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          44.13991769547325\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chi-Square Statistic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.064177931324457,\n        \"min\": 11.485617937157294,\n        \"max\": 26.392469708204196,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          26.392469708204196\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p-value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0003307827990601107,\n        \"min\": 2.7862461297152396e-07,\n        \"max\": 0.0007013680421027408,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2.7862461297152396e-07\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "result_dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0f6c2364-51e9-453c-9f94-702fbbde844a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Level A</th>\n",
              "      <th>Level B</th>\n",
              "      <th>Played A before B</th>\n",
              "      <th>Count</th>\n",
              "      <th># Switched B</th>\n",
              "      <th># Not Switched B</th>\n",
              "      <th>% Switched B</th>\n",
              "      <th>Difference</th>\n",
              "      <th>Expected</th>\n",
              "      <th>Chi-Square Statistic</th>\n",
              "      <th>p-value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bayou-reef-decision</td>\n",
              "      <td>coral-hunting-lions</td>\n",
              "      <td>Y</td>\n",
              "      <td>124</td>\n",
              "      <td>20</td>\n",
              "      <td>104</td>\n",
              "      <td>16.13%</td>\n",
              "      <td>26.14%</td>\n",
              "      <td>44.1399176955</td>\n",
              "      <td>26.3924697082</td>\n",
              "      <td>0.0000002786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bayou-reef-decision</td>\n",
              "      <td>coral-hunting-lions</td>\n",
              "      <td>N</td>\n",
              "      <td>362</td>\n",
              "      <td>153</td>\n",
              "      <td>209</td>\n",
              "      <td>42.27%</td>\n",
              "      <td>26.14%</td>\n",
              "      <td>128.8600823045</td>\n",
              "      <td>26.3924697082</td>\n",
              "      <td>0.0000002786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bayou-hide-n-seek</td>\n",
              "      <td>coral-hunting-lions</td>\n",
              "      <td>Y</td>\n",
              "      <td>148</td>\n",
              "      <td>35</td>\n",
              "      <td>113</td>\n",
              "      <td>23.65%</td>\n",
              "      <td>18.40%</td>\n",
              "      <td>54.1680000000</td>\n",
              "      <td>14.4142107178</td>\n",
              "      <td>0.0001466912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bayou-hide-n-seek</td>\n",
              "      <td>coral-hunting-lions</td>\n",
              "      <td>N</td>\n",
              "      <td>352</td>\n",
              "      <td>148</td>\n",
              "      <td>204</td>\n",
              "      <td>42.05%</td>\n",
              "      <td>18.40%</td>\n",
              "      <td>128.8320000000</td>\n",
              "      <td>14.4142107178</td>\n",
              "      <td>0.0001466912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bayou-methanogen</td>\n",
              "      <td>coral-hunting-lions</td>\n",
              "      <td>Y</td>\n",
              "      <td>162</td>\n",
              "      <td>41</td>\n",
              "      <td>121</td>\n",
              "      <td>25.31%</td>\n",
              "      <td>15.97%</td>\n",
              "      <td>58.5889328063</td>\n",
              "      <td>11.4856179372</td>\n",
              "      <td>0.0007013680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>bayou-methanogen</td>\n",
              "      <td>coral-hunting-lions</td>\n",
              "      <td>N</td>\n",
              "      <td>344</td>\n",
              "      <td>142</td>\n",
              "      <td>202</td>\n",
              "      <td>41.28%</td>\n",
              "      <td>15.97%</td>\n",
              "      <td>124.4110671937</td>\n",
              "      <td>11.4856179372</td>\n",
              "      <td>0.0007013680</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f6c2364-51e9-453c-9f94-702fbbde844a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f6c2364-51e9-453c-9f94-702fbbde844a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f6c2364-51e9-453c-9f94-702fbbde844a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c728a23c-89a0-4e64-909c-1119cca8d881\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c728a23c-89a0-4e64-909c-1119cca8d881')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c728a23c-89a0-4e64-909c-1119cca8d881 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               Level A              Level B Played A before B Count  \\\n",
              "0  bayou-reef-decision  coral-hunting-lions                 Y   124   \n",
              "1  bayou-reef-decision  coral-hunting-lions                 N   362   \n",
              "2    bayou-hide-n-seek  coral-hunting-lions                 Y   148   \n",
              "3    bayou-hide-n-seek  coral-hunting-lions                 N   352   \n",
              "4     bayou-methanogen  coral-hunting-lions                 Y   162   \n",
              "5     bayou-methanogen  coral-hunting-lions                 N   344   \n",
              "\n",
              "  # Switched B # Not Switched B % Switched B Difference       Expected  \\\n",
              "0           20              104       16.13%     26.14%  44.1399176955   \n",
              "1          153              209       42.27%     26.14% 128.8600823045   \n",
              "2           35              113       23.65%     18.40%  54.1680000000   \n",
              "3          148              204       42.05%     18.40% 128.8320000000   \n",
              "4           41              121       25.31%     15.97%  58.5889328063   \n",
              "5          142              202       41.28%     15.97% 124.4110671937   \n",
              "\n",
              "   Chi-Square Statistic      p-value  \n",
              "0         26.3924697082 0.0000002786  \n",
              "1         26.3924697082 0.0000002786  \n",
              "2         14.4142107178 0.0001466912  \n",
              "3         14.4142107178 0.0001466912  \n",
              "4         11.4856179372 0.0007013680  \n",
              "5         11.4856179372 0.0007013680  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def process_dataframe(LevelApacks, LevelB, macro_user_list_yes, macro_user_list_no, macro_counter_yes_switch, macro_counter_no_switch, n):\n",
        "\n",
        "    df = pd.DataFrame(columns=['Level A', 'Level B', 'Played A before B', 'Count', '# Switched B'])\n",
        "\n",
        "    # Populate the DataFrame\n",
        "    for i, level_a in enumerate(LevelApacks):\n",
        "        for j in range(2):\n",
        "            level_b = LevelB\n",
        "            played_before_b = 'Y' if j == 0 else 'N'\n",
        "            count = macro_user_list_yes[i] if j == 0 else macro_user_list_no[i]\n",
        "            switch_b = macro_counter_yes_switch[i] if j == 0 else macro_counter_no_switch[i]\n",
        "\n",
        "            new_row = pd.DataFrame({'Level A': [level_a], 'Level B': [level_b], 'Played A before B': [played_before_b], 'Count': [count], '# Switched B': [switch_b]})\n",
        "            df = pd.concat([df, new_row], ignore_index=True)\n",
        "\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    df['% Switched B'] = df['# Switched B'] / df['Count']\n",
        "\n",
        "    df['Difference'] = df.groupby('Level A')['% Switched B'].diff()\n",
        "    df['Difference'] = df.groupby('Level A')['Difference'].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "    df = df.sort_values(by=['Difference', 'Level A', 'Played A before B'], ascending=[False, True, False])\n",
        "\n",
        "    df['% Switched B'] = df['% Switched B'] * 100\n",
        "    df['% Switched B'] = df['% Switched B'].map('{:.2f}%'.format)\n",
        "\n",
        "    df['Difference'] = df['Difference'] * 100\n",
        "    df['Difference'] = df['Difference'].map('{:.2f}%'.format)\n",
        "    df.insert(5, \"# Not Switched B\", df['Count'] - df['# Switched B'])\n",
        "\n",
        "    df_grouped = df.groupby(\"Level A\")[['# Switched B', '# Not Switched B']].transform('sum')\n",
        "    df['Expected'] = ((df['# Switched B'] + df['# Not Switched B']) * df_grouped['# Switched B']) / (df_grouped['# Switched B'] + df_grouped['# Not Switched B'])\n",
        "\n",
        "    unique_levels = df['Level A'].unique()\n",
        "    chi_stats = []\n",
        "    p_values = []\n",
        "\n",
        "    for level in unique_levels:\n",
        "        subset = df[df['Level A'] == level]\n",
        "        observed = subset['# Switched B'].tolist()\n",
        "        expected = subset['Expected'].tolist()\n",
        "\n",
        "        observed_forchi2 = subset[['# Switched B', '# Not Switched B']].copy()\n",
        "\n",
        "        # Perform chi-square test\n",
        "        chi2, p, _, _ = chi2_contingency(observed_forchi2)\n",
        "        chi_stats.append(chi2)\n",
        "        p_values.append(p)\n",
        "\n",
        "    result_df = pd.DataFrame({'Level A': unique_levels, 'Chi-Square Statistic': chi_stats, 'p-value': p_values})\n",
        "    df = df.merge(result_df, on='Level A', how='left')\n",
        "\n",
        "\n",
        "    ######### Modify the DataFrame to keep only the first n*2 rows #########\n",
        "    df = df.iloc[:n*2]\n",
        "\n",
        "    ######### Extract and return the first n \"Level A\" values #########\n",
        "    level_a_first_n = df['Level A'].iloc[range(0, n*2, 2)].unique().tolist()\n",
        "    return df, level_a_first_n\n",
        "\n",
        "# Example of calling the function with n=3\n",
        "result_dataframe, level_a_first_n = process_dataframe(LevelApacks, LevelB, macro_user_list_yes, macro_user_list_no, macro_counter_yes_switch, macro_counter_no_switch, n=3)\n",
        "result_dataframe\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUDgaJx0JqMW"
      },
      "source": [
        "# III. Construct regression table\n",
        "\n",
        "- This section only consider the n number (defined in Session II) of previous jobs prior to the target job with the highest chi-square coefficient to compile the regression table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p-_XiMSUPRL",
        "outputId": "6706fc2a-dc20-4f1d-a4e5-4920b1c78d1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**-------------------------------- bayou-reef-decision --------------------------------**\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.540631\n",
            "         Iterations 6\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:             Complete_B   No. Observations:                  397\n",
            "Model:                          Logit   Df Residuals:                      387\n",
            "Method:                           MLE   Df Model:                            9\n",
            "Date:                Thu, 11 Apr 2024   Pseudo R-squ.:                  0.1969\n",
            "Time:                        19:31:19   Log-Likelihood:                -214.63\n",
            "converged:                       True   LL-Null:                       -267.27\n",
            "Covariance Type:            nonrobust   LLR p-value:                 1.345e-18\n",
            "===============================================================================\n",
            "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
            "-------------------------------------------------------------------------------\n",
            "const          -0.0558      0.661     -0.084      0.933      -1.351       1.240\n",
            "Complete_A      1.5536      0.309      5.025      0.000       0.948       2.160\n",
            "Arg_above_2    -0.0748      0.097     -0.772      0.440      -0.265       0.115\n",
            "Mod_above_2     0.3404      0.095      3.593      0.000       0.155       0.526\n",
            "Exp_above_2     0.2385      0.119      2.006      0.045       0.005       0.472\n",
            "Time            0.0012      0.001      1.183      0.237      -0.001       0.003\n",
            "Job            -0.1310      0.054     -2.414      0.016      -0.237      -0.025\n",
            "Task            0.0120      0.019      0.631      0.528      -0.025       0.049\n",
            "Biome           0.1635      0.230      0.712      0.477      -0.287       0.614\n",
            "Session        -0.0012      0.003     -0.456      0.648      -0.006       0.004\n",
            "===============================================================================\n",
            "**-------------------------------- bayou-hide-n-seek --------------------------------**\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.546222\n",
            "         Iterations 6\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:             Complete_B   No. Observations:                  397\n",
            "Model:                          Logit   Df Residuals:                      387\n",
            "Method:                           MLE   Df Model:                            9\n",
            "Date:                Thu, 11 Apr 2024   Pseudo R-squ.:                  0.1886\n",
            "Time:                        19:31:24   Log-Likelihood:                -216.85\n",
            "converged:                       True   LL-Null:                       -267.27\n",
            "Covariance Type:            nonrobust   LLR p-value:                 1.067e-17\n",
            "===============================================================================\n",
            "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
            "-------------------------------------------------------------------------------\n",
            "const          -0.0334      0.660     -0.051      0.960      -1.326       1.260\n",
            "Complete_A      1.3816      0.294      4.707      0.000       0.806       1.957\n",
            "Arg_above_2    -0.0767      0.096     -0.796      0.426      -0.266       0.112\n",
            "Mod_above_2     0.3445      0.095      3.636      0.000       0.159       0.530\n",
            "Exp_above_2     0.2334      0.118      1.977      0.048       0.002       0.465\n",
            "Time            0.0012      0.001      1.232      0.218      -0.001       0.003\n",
            "Job            -0.1291      0.054     -2.404      0.016      -0.234      -0.024\n",
            "Task            0.0113      0.019      0.600      0.549      -0.026       0.048\n",
            "Biome           0.1560      0.229      0.680      0.496      -0.294       0.606\n",
            "Session        -0.0008      0.003     -0.320      0.749      -0.006       0.004\n",
            "===============================================================================\n",
            "**-------------------------------- bayou-methanogen --------------------------------**\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.547640\n",
            "         Iterations 6\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:             Complete_B   No. Observations:                  397\n",
            "Model:                          Logit   Df Residuals:                      387\n",
            "Method:                           MLE   Df Model:                            9\n",
            "Date:                Thu, 11 Apr 2024   Pseudo R-squ.:                  0.1865\n",
            "Time:                        19:31:29   Log-Likelihood:                -217.41\n",
            "converged:                       True   LL-Null:                       -267.27\n",
            "Covariance Type:            nonrobust   LLR p-value:                 1.804e-17\n",
            "===============================================================================\n",
            "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
            "-------------------------------------------------------------------------------\n",
            "const          -0.0207      0.661     -0.031      0.975      -1.316       1.275\n",
            "Complete_A      1.2742      0.274      4.648      0.000       0.737       1.812\n",
            "Arg_above_2    -0.0927      0.096     -0.968      0.333      -0.280       0.095\n",
            "Mod_above_2     0.3966      0.097      4.100      0.000       0.207       0.586\n",
            "Exp_above_2     0.1809      0.117      1.543      0.123      -0.049       0.411\n",
            "Time            0.0012      0.001      1.217      0.224      -0.001       0.003\n",
            "Job            -0.1203      0.053     -2.262      0.024      -0.225      -0.016\n",
            "Task            0.0121      0.019      0.648      0.517      -0.024       0.049\n",
            "Biome           0.1066      0.229      0.465      0.642      -0.342       0.556\n",
            "Session        -0.0011      0.003     -0.430      0.667      -0.006       0.004\n",
            "===============================================================================\n"
          ]
        }
      ],
      "source": [
        "def process_levels(data, LevelApacks, LevelB, num_check):\n",
        "    num_levelA = 1\n",
        "\n",
        "    for LevelA in LevelApacks:\n",
        "        if num_levelA > num_check:\n",
        "            break\n",
        "\n",
        "        if LevelA == \"kelp-shop-welcome\":\n",
        "            continue\n",
        "\n",
        "        print(\"**--------------------------------\", LevelA, \"--------------------------------**\")\n",
        "\n",
        "        x = pd.DataFrame(columns=['user_id', 'Level', 'Complete_A', 'Complete_B',\n",
        "                                  'Arg_above_2', 'Mod_above_2', 'Exp_above_2',\n",
        "                                  'Time', 'Job', 'Task', 'Biome', 'Session'])\n",
        "\n",
        "        # Filter user IDs for LevelB\n",
        "        user_ids_levelb = data[data['job_string'] == LevelB]['user_id'].unique()\n",
        "\n",
        "        # Iterate over each user_id\n",
        "        for user_id in user_ids_levelb:\n",
        "            user_data = data[data['user_id'] == user_id]\n",
        "\n",
        "\n",
        "            #【Feature 1-2: Complete_A, Complete_B】: Calculate Complete_A and Complete_B\n",
        "            complete_a = 1 if any((user_data['job_string'] == LevelA) & (user_data['event_change'] == 'completed')) else 0\n",
        "            complete_b = 1 if any((user_data['job_string'] == LevelB) & (user_data['event_change'] == 'completed')) else 0\n",
        "\n",
        "            #【Feature 3-5: unique_job_arg_count, unique_job_mod_count, unique_job_exp_count】: Count the number of jobs [completed] where each difficulty parameter > 2\n",
        "            # Select rows up to and including the first 'LevelB' occurrence\n",
        "            levelb_index = user_data[user_data['job_string'] == LevelB].index.min()\n",
        "            user_data_levelb = user_data.loc[:levelb_index]\n",
        "\n",
        "            filtered_df = user_data_levelb[user_data_levelb['event_change'] == 'completed']   # Which jobs has the student completed so far?\n",
        "                                                                                              # Please change 'filtered_df' to 'user_data_levelb' if we want to include any job student has accepted\n",
        "\n",
        "            unique_job_arg_count = filtered_df[filtered_df['Argumentation'] > 2]['job_string'].nunique()\n",
        "            unique_job_mod_count = filtered_df[filtered_df['Modeling'] > 2]['job_string'].nunique()\n",
        "            unique_job_exp_count = filtered_df[filtered_df['Experimentation'] > 2]['job_string'].nunique()\n",
        "\n",
        "            #【Feature 6: time_diff】: Time spent so far in hours\n",
        "            time_diff  = user_data['time_diff'].sum() / 3600\n",
        "\n",
        "            #【Feature 7-8: job_sum, task_sum】: Sum Job and Task student has completed\n",
        "            job_sum = user_data_levelb['job'].sum()\n",
        "            task_sum = user_data_levelb['task'].sum()\n",
        "\n",
        "            #【Feature 9: Biome】: Number of Biome Student has been to\n",
        "            biome = user_data_levelb['job_string'].str.split('-').str[0].nunique()\n",
        "\n",
        "            #【Feature 10: time_diff】: Number of time paused (unique session id) so far\n",
        "            session  = user_data['session'].sum() - 1\n",
        "\n",
        "\n",
        "            # Append to DataFrame x\n",
        "            new_row = {'user_id': user_id, 'Level': LevelA, 'Complete_A': complete_a, 'Complete_B': complete_b,\n",
        "                      'Arg_above_2': unique_job_arg_count, 'Mod_above_2': unique_job_mod_count, 'Exp_above_2': unique_job_exp_count,\n",
        "                      'Time': time_diff, 'Job': job_sum, 'Task': task_sum, 'Biome': biome, 'Session': session}\n",
        "\n",
        "\n",
        "            x = pd.concat([x, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "        # Drop rows where any NaN values exist due to incomplete log file\n",
        "        x = x.dropna()\n",
        "\n",
        "        # If Biome is the same all the time, drop it\n",
        "        if x['Biome'].nunique() == 1:\n",
        "          x = x.drop_duplicates(subset='Biome', keep=False)\n",
        "\n",
        "        # Selecting the independent variables (excluding 'user_id' and 'Complete_B')\n",
        "        X = x.drop(['user_id', 'Complete_B', 'Level'], axis=1)\n",
        "\n",
        "        # Adding a constant to the model (intercept)\n",
        "        X = sm.add_constant(X)\n",
        "\n",
        "        # The dependent variable\n",
        "        y = x['Complete_B']\n",
        "\n",
        "        # Fit the regression model\n",
        "        model = sm.Logit(y.astype(float), X.astype(float))\n",
        "        result = model.fit(method='bfgs', maxiter=100, tol=1e-2)\n",
        "\n",
        "        # Print the summary of the regression\n",
        "        print(result.summary())\n",
        "\n",
        "        # Print the p-value for 'Complete_A'\n",
        "        # p_value_complete_a = result.pvalues['Complete_A']\n",
        "        # print(f\"P-value for {LevelA}: {p_value_complete_a}\")\n",
        "\n",
        "        num_levelA += 1\n",
        "\n",
        "LevelApacks = level_a_first_n\n",
        "process_levels(data, LevelApacks, LevelB, num_check = 300)  ###### 【Customizable item】\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
